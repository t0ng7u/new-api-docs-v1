---
title: OpenAI Responses
---

<Callout type="info" title="Official Documentation">
  [OpenAI Responses](https://platform.openai.com/docs/api-reference/responses)
</Callout>

## ğŸ“ Introduction

OpenAI's state-of-the-art model response interface. Supports text and image input, as well as text output. Create stateful interactions with models, using the output of previous responses as input. Extend the model's capabilities with built-in tools such as file search, web search, and computer use. Use function calling to allow the model to access external systems and data.

Related guides can be found on the OpenAI official website: [Responses](https://platform.openai.com/docs/guides/migrate-to-responses)

## ğŸ’¡ Request Examples

### Basic Text Response âœ…

```bash
curl https://ä½ çš„newapiæœåŠ¡å™¨åœ°å€/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "input": "è®²ä¸€ä¸ªä¸‰å¥è¯çš„å…³äºç‹¬è§’å…½çš„ç¡å‰æ•…äº‹ã€‚"
  }'
```

**Response Example:**

```json
{
  "id": "resp_67ccd2bed1ec8190b14f964abc0542670bb6a6b452d3795b",
  "object": "response",
  "created_at": 1741476542,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-4.1",
  "output": [
    {
      "type": "message",
      "id": "msg_67ccd2bf17f0819081ff3bb2cf6508e60bb6a6b452d3795b",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "åœ¨ä¸€ä¸ªå®é™çš„æœˆå¤œä¸‹ï¼Œä¸€åªåå«ç’ç±³å¨œçš„ç‹¬è§’å…½å‘ç°äº†ä¸€ä¸ªå€’æ˜ ç€æ˜Ÿæ˜Ÿçš„éšè—æ°´æ± ã€‚å½“å¥¹å°†ç‹¬è§’æµ¸å…¥æ°´ä¸­æ—¶ï¼Œæ°´æ± å¼€å§‹é—ªçƒï¼Œæ˜¾ç°å‡ºé€šå¾€ä¸€ä¸ªæœ‰ç€æ— å°½å¤œç©ºçš„é­”æ³•ä¸–ç•Œçš„è·¯å¾„ã€‚å……æ»¡å¥½å¥‡ï¼Œç’ç±³å¨œä¸ºæ‰€æœ‰åšæ¢¦çš„äººè®¸ä¸‹æ„¿æœ›ï¼Œå¸Œæœ›ä»–ä»¬èƒ½æ‰¾åˆ°è‡ªå·±çš„éšè—é­”æ³•ï¼Œå½“å¥¹å›å¤´æœ›å»ï¼Œå¥¹çš„è¹„å°åƒæ˜Ÿå°˜ä¸€æ ·é—ªçƒã€‚",
          "annotations": []
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 36,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 87,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 123
  },
  "user": null,
  "metadata": {}
}
```

### Image Analysis Response âœ…

```bash
curl https://ä½ çš„newapiæœåŠ¡å™¨åœ°å€/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "input": [
      {
        "role": "user",
        "content": [
          {"type": "input_text", "text": "æè¿°è¿™å¼ å›¾ç‰‡ä¸­çš„å†…å®¹"},
          {
            "type": "input_image",
            "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
          }
        ]
      }
    ]
  }'
```

**Response Example:**

```json
{
  "id": "resp_67ccd3a9da748190baa7f1570fe91ac604becb25c45c1d41",
  "object": "response",
  "created_at": 1741476777,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-4.1",
  "output": [
    {
      "type": "message",
      "id": "msg_67ccd3acc8d48190a77525dc6de64b4104becb25c45c1d41",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "è¿™å¼ å›¾ç‰‡å±•ç¤ºäº†ä¸€æ¡æœ¨åˆ¶æ ˆé“æˆ–å°å¾„ç©¿è¿‡èŒ‚å¯†çš„ç»¿è‰²è‰åœ°ï¼Œä¸Šæ–¹æ˜¯ç‚¹ç¼€ç€å‡ æœµäº‘çš„è“å¤©ã€‚åœºæ™¯å‘ˆç°å‡ºä¸€ä¸ªå®é™çš„è‡ªç„¶åŒºåŸŸï¼Œå¯èƒ½æ˜¯å…¬å›­æˆ–è‡ªç„¶ä¿æŠ¤åŒºã€‚èƒŒæ™¯ä¸­æœ‰æ ‘æœ¨å’ŒçŒæœ¨ä¸›ã€‚æ•´ä¸ªæ™¯è§‚å±•ç°å‡ºå’Œè°çš„è‡ªç„¶ç¯å¢ƒï¼Œæ ˆé“ä¸ºæ¸¸å®¢æä¾›äº†ä¸€æ¡ç©¿è¿‡æ¹¿åœ°æˆ–è‰åŸè€Œä¸å½±å“å‘¨å›´ç”Ÿæ€ç³»ç»Ÿçš„è·¯å¾„ã€‚",
          "annotations": []
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 328,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 52,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 380
  },
  "user": null,
  "metadata": {}
}
```

### Web Search Tool âœ…

```bash
curl https://ä½ çš„newapiæœåŠ¡å™¨åœ°å€/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "tools": [{ "type": "web_search_preview" }],
    "input": "ä»Šå¤©æœ‰ä»€ä¹ˆç§¯ææ­£é¢çš„æ–°é—»?"
  }'
```

**Response Example:**

```json
{
  "id": "resp_67ccf18ef5fc8190b16dbee19bc54e5f087bb177ab789d5c",
  "object": "response",
  "created_at": 1741484430,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-4.1",
  "output": [
    {
      "type": "web_search_call",
      "id": "ws_67ccf18f64008190a39b619f4c8455ef087bb177ab789d5c",
      "status": "completed"
    },
    {
      "type": "message",
      "id": "msg_67ccf190ca3881909d433c50b1f6357e087bb177ab789d5c",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "æˆªè‡³ä»Šå¤©ï¼Œ2025å¹´3æœˆ9æ—¥ï¼Œä¸€åˆ™å€¼å¾—å…³æ³¨çš„ç§¯ææ–°é—»æ˜¯ä¸­å›½ç§‘å­¦å®¶åœ¨å¯å†ç”Ÿèƒ½æºé¢†åŸŸå–å¾—é‡å¤§çªç ´ï¼ŒæˆåŠŸç ”å‘å‡ºä¸€ç§æ–°å‹é«˜æ•ˆå¤ªé˜³èƒ½ç”µæ± ï¼Œè½¬åŒ–ç‡è¾¾åˆ°äº†åˆ›çºªå½•çš„35%ï¼Œè¿™å¯èƒ½ä¼šæå¤§æ¨åŠ¨æ¸…æ´èƒ½æºçš„æ™®åŠå’Œåº”ç”¨ã€‚è¿™é¡¹æŠ€æœ¯é¢„è®¡å°†ä½¿å¤ªé˜³èƒ½å‘ç”µæˆæœ¬é™ä½çº¦40%ï¼Œä¸ºå…¨çƒå‡å°‘ç¢³æ’æ”¾æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
          "annotations": [
            {
              "type": "url_citation",
              "start_index": 42,
              "end_index": 100,
              "url": "https://example.com/renewable-energy-breakthrough/?utm_source=chatgpt.com",
              "title": "ä¸­å›½ç§‘å­¦å®¶åœ¨å¯å†ç”Ÿèƒ½æºé¢†åŸŸå–å¾—é‡å¤§çªç ´"
            },
            {
              "type": "url_citation",
              "start_index": 101,
              "end_index": 150,
              "url": "https://example.com/solar-cell-efficiency-record/?utm_source=chatgpt.com",
              "title": "æ–°å‹é«˜æ•ˆå¤ªé˜³èƒ½ç”µæ± è½¬åŒ–ç‡åˆ›çºªå½•"
            },
            {
              "type": "url_citation",
              "start_index": 151,
              "end_index": 200,
              "url": "https://example.com/clean-energy-cost-reduction/?utm_source=chatgpt.com",
              "title": "å¤ªé˜³èƒ½å‘ç”µæˆæœ¬æœ‰æœ›é™ä½40%"
            }
          ]
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [
    {
      "type": "web_search_preview",
      "domains": [],
      "search_context_size": "medium",
      "user_location": {
        "type": "approximate",
        "city": null,
        "country": "US",
        "region": null,
        "timezone": null
      }
    }
  ],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 328,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 356,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 684
  },
  "user": null,
  "metadata": {}
}
```

### File Search Tool âœ…

```bash
curl https://ä½ çš„newapiæœåŠ¡å™¨åœ°å€/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "tools": [{
      "type": "file_search",
      "vector_store_ids": ["vs_1234567890"],
      "max_num_results": 20
    }],
    "input": "å¤ä»£æ£•é¾™æœ‰å“ªäº›ç‰¹æ€§å’Œå±æ€§?"
  }'
```

**Response Example:**

```json
{
  "id": "resp_67ccf4c55fc48190b71bd0463ad3306d09504fb6872380d7",
  "object": "response",
  "created_at": 1741485253,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-4.1",
  "output": [
    {
      "type": "file_search_call",
      "id": "fs_67ccf4c63cd08190887ef6464ba5681609504fb6872380d7",
      "status": "completed",
      "queries": ["å¤ä»£æ£•é¾™çš„ç‰¹æ€§å’Œå±æ€§"],
      "results": null
    },
    {
      "type": "message",
      "id": "msg_67ccf4c93e5c81909d595b369351a9d309504fb6872380d7",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "æ ¹æ®èµ„æ–™ï¼Œå¤ä»£æ£•é¾™å…·æœ‰ä»¥ä¸‹ç‰¹æ€§å’Œå±æ€§ï¼š\n\n1. ç‰©ç†ç‰¹å¾ï¼šå¤ä»£æ£•é¾™ä½“å‹åºå¤§ï¼Œä½“é•¿å¯è¾¾25-30ç±³ï¼Œç¿¼å±•çº¦35ç±³ã€‚å®ƒä»¬çš„é³ç‰‡å‘ˆæ·±æ£•è‰²è‡³é“œè‰²ï¼Œéšç€å¹´é¾„å¢é•¿ä¼šå˜å¾—æ›´åŠ æš—æ²‰ã€‚å¤´éƒ¨æœ‰ç‰¹å¾æ€§çš„åŒè§’å’Œè„Šåˆºï¼Œä¸‹é¢šå¼ºå£®ï¼Œé€‚åˆæ’•è£‚çŒç‰©ã€‚\n\n2. èƒ½åŠ›ï¼šå®ƒä»¬èƒ½å–·åå¼ºåŠ›çš„é…¸æ¶²ï¼Œå¯¹ç›®æ ‡é€ æˆä¸¥é‡è…èš€ä¼¤å®³ã€‚å¤ä»£æ£•é¾™è¿˜æ‹¥æœ‰å‡ºè‰²çš„æ˜åœ°èƒ½åŠ›ï¼Œå¸¸åœ¨æ²™æ¼ æˆ–å±±åœ°æŒ–æ˜å¤æ‚çš„å·¢ç©´ç³»ç»Ÿã€‚\n\n3. æ™ºåŠ›ï¼šè¢«è®¤ä¸ºæ˜¯é¾™æ—ä¸­æœ€ä¸ºç‹¡çŒ¾å’Œæœ‰è€å¿ƒçš„å“ç§ï¼Œæ™ºåŠ›æé«˜ï¼Œç²¾é€šå¤šç§è¯­è¨€ï¼Œå¹¶å…·æœ‰å¤æ‚çš„æˆ˜æœ¯æ€ç»´ã€‚\n\n4. æ –æ¯åœ°ï¼šä¸»è¦æ –æ¯åœ¨å¹²æ—±çš„å±±åœ°å’Œæ²™æ¼ åœ°åŒºï¼Œå–œæ¬¢ç‚çƒ­å¹²ç‡¥çš„ç¯å¢ƒã€‚\n\n5. å®è—ï¼šå¤ä»£æ£•é¾™ä»¥å…¶åºå¤§çš„å®è—é—»åï¼Œç‰¹åˆ«å–œçˆ±æ”¶é›†é“œå¸ã€çº¢å®çŸ³å’Œç«ç„°é­”æ³•ç‰©å“ã€‚\n\n6. å¯¿å‘½ï¼šæ˜¯æ‰€æœ‰é¾™ç§ä¸­å¯¿å‘½æœ€é•¿çš„ä¹‹ä¸€ï¼Œå¯æ´»2000-2500å¹´ï¼Œéšç€å¹´é¾„å¢é•¿å…¶åŠ›é‡å’Œé­”æ³•èƒ½åŠ›ä¹Ÿä¼šå¢å¼ºã€‚\n\n7. æ€§æ ¼ï¼šæåº¦é¢†åœ°æ„è¯†å¼ºï¼Œæ€§æ ¼æš´èºæ˜“æ€’ï¼Œå¯¹ä¾µå…¥è€…æ¯«ä¸ç•™æƒ…ï¼Œä½†ä¹Ÿä»¥å…¶ç½•è§çš„è€å¿ƒè‘—ç§°ï¼Œèƒ½ä¸ºå¤ä»‡ç­‰å¾…å‡ ä¸ªä¸–çºªã€‚",
          "annotations": [
            {
              "type": "file_citation",
              "index": 80,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            },
            {
              "type": "file_citation",
              "index": 233,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            },
            {
              "type": "file_citation",
              "index": 345,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            },
            {
              "type": "file_citation",
              "index": 420,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            },
            {
              "type": "file_citation",
              "index": 520,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            },
            {
              "type": "file_citation",
              "index": 580,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            },
            {
              "type": "file_citation",
              "index": 655,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            },
            {
              "type": "file_citation",
              "index": 781,
              "file_id": "file-4wDz5b167pAf72nx1h9eiN",
              "filename": "dragons.pdf"
            }
          ]
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [
    {
      "type": "file_search",
      "filters": null,
      "max_num_results": 20,
      "ranking_options": {
        "ranker": "auto",
        "score_threshold": 0.0
      },
      "vector_store_ids": ["vs_1234567890"]
    }
  ],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 18307,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 348,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 18655
  },
  "user": null,
  "metadata": {}
}
```

### Streaming Response âœ…

```bash
curl https://ä½ çš„newapiæœåŠ¡å™¨åœ°å€/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "instructions": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚",
    "input": "ä½ å¥½ï¼",
    "stream": true
  }'
```

**Streaming Response Example:**

```
event: response.created
data: {"type":"response.created","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"in_progress","error":null,"incomplete_details":null,"instructions":"ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚","max_output_tokens":null,"model":"gpt-4.1-2025-04-14","output":[],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":null,"user":null,"metadata":{}}}

event: response.in_progress
data: {"type":"response.in_progress","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"in_progress","error":null,"incomplete_details":null,"instructions":"ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚","max_output_tokens":null,"model":"gpt-4.1-2025-04-14","output":[],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":null,"user":null,"metadata":{}}}

event: response.output_item.added
data: {"type":"response.output_item.added","output_index":0,"item":{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"in_progress","role":"assistant","content":[]}}

event: response.content_part.added
data: {"type":"response.content_part.added","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"part":{"type":"output_text","text":"","annotations":[]}}

event: response.output_text.delta
data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"ä½ å¥½"}

event: response.output_text.delta
data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"ï¼"}

event: response.output_text.delta
data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":" æˆ‘"}

event: response.output_text.delta
data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"èƒ½"}

event: response.output_text.delta
data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"ä¸º"}

event: response.output_text.delta
data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"æ‚¨"}

event: response.output_text.delta
data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"æä¾›"}

event: response.output_text.delta
data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"ä»€ä¹ˆ"}

event: response.output_text.delta
data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"å¸®åŠ©"}

event: response.output_text.delta
data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"å—"}

event: response.output_text.delta
data: {"type":"response.output_text.delta","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"delta":"ï¼Ÿ"}

event: response.output_text.done
data: {"type":"response.output_text.done","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"text":"ä½ å¥½ï¼ æˆ‘èƒ½ä¸ºæ‚¨æä¾›ä»€ä¹ˆå¸®åŠ©å—ï¼Ÿ"}

event: response.content_part.done
data: {"type":"response.content_part.done","item_id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","output_index":0,"content_index":0,"part":{"type":"output_text","text":"ä½ å¥½ï¼ æˆ‘èƒ½ä¸ºæ‚¨æä¾›ä»€ä¹ˆå¸®åŠ©å—ï¼Ÿ","annotations":[]}}

event: response.output_item.done
data: {"type":"response.output_item.done","output_index":0,"item":{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"completed","role":"assistant","content":[{"type":"output_text","text":"ä½ å¥½ï¼ æˆ‘èƒ½ä¸ºæ‚¨æä¾›ä»€ä¹ˆå¸®åŠ©å—ï¼Ÿ","annotations":[]}]}}

event: response.completed
data: {"type":"response.completed","response":{"id":"resp_67c9fdcecf488190bdd9a0409de3a1ec07b8b0ad4e5eb654","object":"response","created_at":1741290958,"status":"completed","error":null,"incomplete_details":null,"instructions":"ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚","max_output_tokens":null,"model":"gpt-4.1-2025-04-14","output":[{"id":"msg_67c9fdcf37fc8190ba82116e33fb28c507b8b0ad4e5eb654","type":"message","status":"completed","role":"assistant","content":[{"type":"output_text","text":"ä½ å¥½ï¼ æˆ‘èƒ½ä¸ºæ‚¨æä¾›ä»€ä¹ˆå¸®åŠ©å—ï¼Ÿ","annotations":[]}]}],"parallel_tool_calls":true,"previous_response_id":null,"reasoning":{"effort":null,"summary":null},"store":true,"temperature":1.0,"text":{"format":{"type":"text"}},"tool_choice":"auto","tools":[],"top_p":1.0,"truncation":"disabled","usage":{"input_tokens":37,"output_tokens":11,"output_tokens_details":{"reasoning_tokens":0},"total_tokens":48},"user":null,"metadata":{}}}
```

### Function Calling âœ…

```bash
curl https://ä½ çš„newapiæœåŠ¡å™¨åœ°å€/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "input": "æ³¢å£«é¡¿ä»Šå¤©çš„å¤©æ°”å¦‚ä½•ï¼Ÿ",
    "tools": [
      {
        "type": "function",
        "name": "get_current_weather",
        "description": "è·å–æŒ‡å®šä½ç½®çš„å½“å‰å¤©æ°”",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "åŸå¸‚å’Œå·ï¼Œä¾‹å¦‚ San Francisco, CA"
            },
            "unit": {
              "type": "string",
              "enum": ["celsius", "fahrenheit"]
            }
          },
          "required": ["location", "unit"]
        }
      }
    ],
    "tool_choice": "auto"
  }'
```

**Response Example:**

```json
{
  "id": "resp_67ca09c5efe0819096d0511c92b8c890096610f474011cc0",
  "object": "response",
  "created_at": 1741294021,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "gpt-4.1-2025-04-14",
  "output": [
    {
      "type": "function_call",
      "id": "fc_67ca09c6bedc8190a7abfec07b1a1332096610f474011cc0",
      "call_id": "call_unLAR8MvFNptuiZK6K6HCy5k",
      "name": "get_current_weather",
      "arguments": "{\"location\":\"æ³¢å£«é¡¿, MA\",\"unit\":\"celsius\"}",
      "status": "completed"
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": null,
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [
    {
      "type": "function",
      "description": "è·å–æŒ‡å®šä½ç½®çš„å½“å‰å¤©æ°”",
      "name": "get_current_weather",
      "parameters": {
        "type": "object",
        "properties": {
          "location": {
            "type": "string",
            "description": "åŸå¸‚å’Œå·ï¼Œä¾‹å¦‚ San Francisco, CA"
          },
          "unit": {
            "type": "string",
            "enum": ["celsius", "fahrenheit"]
          }
        },
        "required": ["location", "unit"]
      },
      "strict": true
    }
  ],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 291,
    "output_tokens": 23,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 314
  },
  "user": null,
  "metadata": {}
}
```

### Reasoning Capabilities âœ…

```bash
curl https://ä½ çš„newapiæœåŠ¡å™¨åœ°å€/v1/responses \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "o3-mini",
    "input": "ä¸€åªå•„æœ¨é¸Ÿèƒ½å•„å¤šå°‘æœ¨å¤´?",
    "reasoning": {
      "effort": "high"
    }
  }'
```

**Response Example:**

```json
{
  "id": "resp_67ccd7eca01881908ff0b5146584e408072912b2993db808",
  "object": "response",
  "created_at": 1741477868,
  "status": "completed",
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "max_output_tokens": null,
  "model": "o1-2024-12-17",
  "output": [
    {
      "type": "message",
      "id": "msg_67ccd7f7b5848190a6f3e95d809f6b44072912b2993db808",
      "status": "completed",
      "role": "assistant",
      "content": [
        {
          "type": "output_text",
          "text": "è¿™æ˜¯ä¸€ä¸ªæºè‡ªè‹±æ–‡ç»•å£ä»¤"How much wood would a woodchuck chuck if a woodchuck could chuck wood"çš„é—®é¢˜ã€‚åœ¨ç°å®ä¸­ï¼Œå•„æœ¨é¸Ÿ(woodpecker)å’ŒåœŸæ‹¨é¼ (woodchuck)æ˜¯ä¸åŒçš„åŠ¨ç‰©ï¼Œè€Œä¸”åœŸæ‹¨é¼ å®é™…ä¸Šå¹¶ä¸"å•„(chuck)"æœ¨å¤´ã€‚\n\nä»ç§‘å­¦è§’åº¦çœ‹ï¼Œå•„æœ¨é¸Ÿæ¯å¤©ç¡®å®ä¼šå•„æ ‘æœ¨ä»¥å¯»æ‰¾é£Ÿç‰©ã€å»ºé€ å·¢ç©´æˆ–è¿›è¡Œé€šè®¯ã€‚ä¸€åªå•„æœ¨é¸Ÿå¹³å‡æ¯å¤©å¯èƒ½å•„æ ‘çº¦8000-12000æ¬¡ï¼Œè§†ç‰©ç§å’Œå…·ä½“ç›®çš„è€Œå®šã€‚å¦‚æœæˆ‘ä»¬å°†è¿™è½¬æ¢ä¸ºæœ¨æé‡ï¼Œå‡è®¾æ¯æ¬¡å•„å‡»ç§»é™¤çº¦0.1-0.2ç«‹æ–¹å˜ç±³çš„æœ¨æï¼Œé‚£ä¹ˆä¸€åªå•„æœ¨é¸Ÿç†è®ºä¸Šæ¯å¤©å¯èƒ½ç§»é™¤çº¦800-2400ç«‹æ–¹å˜ç±³çš„æœ¨æã€‚\n\nç„¶è€Œï¼Œå•„æœ¨é¸Ÿä¸»è¦æ˜¯ä¸ºäº†è§…é£Ÿå’Œç­‘å·¢è€Œå•„æœ¨ï¼Œè€Œä¸æ˜¯å•çº¯åœ°ç§»é™¤æœ¨æï¼Œæ‰€ä»¥è¿™ä¸ªè®¡ç®—åªæ˜¯ä¸€ä¸ªæœ‰è¶£çš„ç†è®ºä¼°ç®—ã€‚",
          "annotations": []
        }
      ]
    }
  ],
  "parallel_tool_calls": true,
  "previous_response_id": null,
  "reasoning": {
    "effort": "high",
    "summary": null
  },
  "store": true,
  "temperature": 1.0,
  "text": {
    "format": {
      "type": "text"
    }
  },
  "tool_choice": "auto",
  "tools": [],
  "top_p": 1.0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 81,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 1035,
    "output_tokens_details": {
      "reasoning_tokens": 832
    },
    "total_tokens": 1116
  },
  "user": null,
  "metadata": {}
}
```

## ğŸ“® Request

### Endpoint

```
POST /v1/responses
```

Create a model response. Provide text or image input to generate text or JSON output. Allow the model to call your own custom code or use built-in tools (such as web search or file search) to use your own data as input for the model response.

### Authentication Method

Include the following in the request header for API key authentication:

```
Authorization: Bearer $NEWAPI_API_KEY
```

Where `$NEWAPI_API_KEY` is your API key.

### Request Body Parameters

#### input

**Type**: string or array  
**Required**: Yes

The text, image, or file input provided to the model to generate a response.

##### Possible Types

| Type                | Description                                                |
| ------------------- | ---------------------------------------------------------- |
| String              | Text input, equivalent to text input with a user role      |
| Array of input items | A list of one or more input items containing different content types |

##### Input Message Object

| Property | Type         | Required | Description                                                                     |
| -------- | ------------ | -------- | ------------------------------------------------------------------------------- |
| content  | string or array | Yes      | The text, image, or audio input provided to the model to generate a response. Can also include previous assistant responses |
| role     | string       | Yes      | The role of the input message. Possible values: `user`, `assistant`, `system`, or `developer` |
| type     | string       | No       | The type of the input message, always `message`                                 |

##### Content Item Types

###### Text Input

| Property | Type   | Required | Description                              |
| -------- | ------ | -------- | ---------------------------------------- |
| text     | string | Yes      | The text input provided to the model     |
| type     | string | Yes      | The type of the input item, always `input_text` |

###### Image Input

| Property  | Type   | Required | Description                                                                         |
| --------- | ------ | -------- | ----------------------------------------------------------------------------------- |
| detail    | string | Yes      | The detail level of the image to send to the model. Possible values: `high`, `low`, or `auto`. Defaults to `auto` |
| type      | string | Yes      | The type of the input item, always `input_image`                                    |
| file_id   | string | No       | The file ID to send to the model                                                    |
| image_url | string | No       | The image URL to send to the model. Can be a full URL or a base64 encoded image in a data URL |

###### File Input

| Property  | Type   | Required | Description                              |
| --------- | ------ | -------- | ---------------------------------------- |
| type      | string | Yes      | The type of the input item, always `input_file` |
| file_data | string | No       | The content of the file to send to the model |
| file_id   | string | No       | The file ID to send to the model         |
| filename  | string | No       | The filename to send to the model        |

##### Output Item Types

###### Output Text

| Property    | Type   | Required | Description                              |
| ----------- | ------ | -------- | ---------------------------------------- |
| text        | string | Yes      | The text output generated by the model   |
| type        | string | Yes      | The type of the output item, always `output_text` |
| annotations | array  | Yes      | Annotations for the text output          |

###### Annotation Types

File Citation:

| Property | Type   | Required | Description                              |
| -------- | ------ | -------- | ---------------------------------------- |
| file_id  | string | Yes      | The ID of the file                       |
| index    | integer | Yes      | The index of the file in the file list   |
| type     | string | Yes      | The type of file citation, always `file_citation` |

URL Citation:

| Property    | Type   | Required | Description                                 |
| ----------- | ------ | -------- | ------------------------------------------- |
| end_index   | integer | Yes      | The index of the last character of the URL citation in the message |
| start_index | integer | Yes      | The index of the first character of the URL citation in the message |
| title       | string | Yes      | The title of the web resource               |
| type        | string | Yes      | The type of URL citation, always `url_citation` |
| url         | string | Yes      | The URL of the web resource                 |

File Path:

| Property | Type   | Required | Description                              |
| -------- | ------ | -------- | ---------------------------------------- |
| file_id  | string | Yes      | The ID of the file                       |
| index    | integer | Yes      | The index of the file in the file list   |
| type     | string | Yes      | The type of file path, always `file_path` |

###### Refusal Response

| Property | Type   | Required | Description                              |
| -------- | ------ | -------- | ---------------------------------------- |
| refusal  | string | Yes      | The model's explanation for refusal      |
| type     | string | Yes      | The type of refusal, always `refusal`    |

##### Tool Call Types

###### File Search Tool Call

| Property | Type       | Required | Description                                                                                     |
| -------- | ---------- | -------- | ----------------------------------------------------------------------------------------------- |
| id       | string     | Yes      | The unique ID of the file search tool call                                                      |
| queries  | array      | Yes      | The queries used to search for files                                                            |
| status   | string     | Yes      | The status of the file search tool call. Possible values include: `in_progress`, `searching`, `incomplete`, or `failed` |
| type     | string     | Yes      | The type of file search tool call, always `file_search_call`                                    |
| results  | array or null | No       | The results of the file search tool call                                                        |

###### Web Search Tool Call

| Property | Type   | Required | Description                                             |
| -------- | ------ | -------- | ------------------------------------------------------- |
| id       | string | Yes      | The unique ID of the web search tool call               |
| status   | string | Yes      | The status of the web search tool call                  |
| type     | string | Yes      | The type of web search tool call, always `web_search_call` |

###### Function Tool Call

| Property  | Type   | Required | Description                                                         |
| --------- | ------ | -------- | ------------------------------------------------------------------- |
| arguments | string | Yes      | The JSON string of arguments passed to the function                 |
| call_id   | string | Yes      | The unique ID of the function tool call generated by the model      |
| name      | string | Yes      | The name of the function to run                                     |
| type      | string | Yes      | The type of function tool call, always `function_call`              |
| id        | string | No       | The unique ID of the function tool call                             |
| status    | string | No       | The status of the item. Possible values: `in_progress`, `completed`, or `incomplete` |

###### Computer Tool Call

| Property              | Type   | Required | Description                                                         |
| --------------------- | ------ | -------- | ------------------------------------------------------------------- |
| action                | object | Yes      | The action of the computer interaction, such as click, drag, etc.   |
| call_id               | string | Yes      | The identifier used when responding to tool call output             |
| id                    | string | Yes      | The unique ID of the computer call                                  |
| pending_safety_checks | array  | Yes      | Pending safety checks for the computer call                         |
| status                | string | Yes      | The status of the item. Possible values: `in_progress`, `completed`, or `incomplete` |
| type                  | string | Yes      | The type of computer call, always `computer_call`                   |

Computer Action Types:

| Action Type  | Description             |
| ------------ | ----------------------- |
| click        | Mouse click operation   |
| double_click | Mouse double click operation |
| drag         | Drag operation          |
| keypress     | Keypress operation      |
| move         | Mouse move operation    |
| screenshot   | Screenshot operation    |
| scroll       | Scroll operation        |
| type         | Text input operation    |
| wait         | Wait operation          |

###### Computer Tool Call Output

| Property                   | Type   | Required | Description                                                             |
| -------------------------- | ------ | -------- | ----------------------------------------------------------------------- |
| call_id                    | string | Yes      | The ID of the computer tool call that produced the output               |
| output                     | object | Yes      | The computer screenshot image used for the computer use tool            |
| type                       | string | Yes      | The type of computer tool call output, always `computer_call_output`    |
| acknowledged_safety_checks | array  | No       | Safety checks reported by the API that have been acknowledged by the developer |
| id                         | string | No       | The ID of the computer tool call output                                 |
| status                     | string | No       | The status of the input message. Possible values: `in_progress`, `completed`, or `incomplete` |

###### Function Tool Call Output

| Property | Type   | Required | Description                                                         |
| -------- | ------ | -------- | ------------------------------------------------------------------- |
| call_id  | string | Yes      | The unique ID of the function tool call generated by the model      |
| output   | string | Yes      | The JSON string of the function tool call output                    |
| type     | string | Yes      | The type of function tool call output, always `function_call_output` |
| id       | string | No       | The unique ID of the function tool call output                      |
| status   | string | No       | The status of the item. Possible values: `in_progress`, `completed`, or `incomplete` |

##### Reasoning Related Items

| Property          | Type         | Required | Description                                                                           |
| ----------------- | ------------ | -------- | ------------------------------------------------------------------------------------- |
| id                | string       | Yes      | The unique identifier for the reasoning content                                       |
| summary           | array        | Yes      | Reasoning text content                                                                |
| type              | string       | Yes      | The type of the object, always `reasoning`                                            |
| encrypted_content | string or null | No       | The encrypted content of the reasoning item - populated when generating a response with the `reasoning.encrypted_content` include parameter |
| status            | string       | No       | The status of the item. Possible values: `in_progress`, `completed`, or `incomplete`  |

Reasoning Summary:

| Property | Type   | Required | Description                                               |
| -------- | ------ | -------- | --------------------------------------------------------- |
| text     | string | Yes      | A brief summary of the reasoning used by the model when generating the response |
| type     | string | Yes      | The type of the object, always `summary_text`             |

##### Item Reference

| Property | Type   | Required | Description                              |
| -------- | ------ | -------- | ---------------------------------------- |
| id       | string | Yes      | The ID of the item to reference          |
| type     | string | No       | The type of item to reference, always `item_reference` |

#### model

**Type**: string  
**Required**: Yes

The ID of the model to use for generating the response, e.g., gpt-4.1 or o3. OpenAI offers various models with different capabilities, performance characteristics, and price points. Please refer to the model guide to browse and compare available models.

#### include

**Type**: array or null  
**Required**: No

Specifies additional output data to include in the model response. Currently supported values include:

| Value                                   | Description                                                      |
| --------------------------------------- | ---------------------------------------------------------------- |
| `file_search_call.results`              | Includes the search results of the file search tool call         |
| `message.input_image.image_url`         | Includes the image URL from the input message                    |
| `computer_call_output.output.image_url` | Includes the image URL from the computer call output             |
| `reasoning.encrypted_content`           | Includes the encrypted version of reasoning tokens in the reasoning item output |

#### instructions

**Type**: string or null  
**Required**: No

Inserts a system (or developer) message as the first item in the model's context.

When used with `previous_response_id`, instructions from the previous response are not carried over to the next response. This makes it easy to switch system (developer) messages in a new response.

#### max_output_tokens

**Type**: integer or null  
**Required**: No

The upper bound on the number of tokens that can be generated for the response, including visible output tokens and reasoning tokens.

#### metadata

**Type**: object  
**Required**: No

A collection of 16 key-value pairs that can be attached to an object. This is useful for storing additional information about the object in a structured format and can be queried via the API or dashboard.

Keys are strings with a maximum length of 64 characters. Values are strings with a maximum length of 512 characters.

#### parallel_tool_calls

**Type**: boolean or null  
**Required**: No  
**Default**: true

Whether the model is allowed to run tool calls in parallel.

#### previous_response_id

**Type**: string or null  
**Required**: No

The unique ID of the model's previous response. Use this parameter to create multi-turn conversations. Learn more about conversation state.

#### reasoning

**Type**: object or null  
**Required**: No  
**Only for o-series models**

Configuration options for the reasoning model.

| Property         | Type         | Required | Description                                                                                                                         |
| ---------------- | ------------ | -------- | ----------------------------------------------------------------------------------------------------------------------------------- |
| effort           | string or null | No       | The effort level for reasoning. Possible values: `low`, `medium`, `high`. Defaults to `medium`. Lowering reasoning effort can speed up response times and reduce the number of tokens used for reasoning in the response |
| summary          | string or null | No       | A summary of the reasoning performed by the model. This is useful for debugging and understanding the model's reasoning process. Possible values: `auto`, `concise`, `detailed` |
| generate_summary | string or null | No       | **Deprecated**: Please use `summary` instead. A summary of the reasoning performed by the model. Possible values: `auto`, `concise`, `detailed` |

#### service_tier

**Type**: string or null  
**Required**: No  
**Default**: auto

Specifies the latency tier used to process the request. This parameter is relevant for customers subscribed to scale tier services:

| Value     | Description                                                                                                                                                          |
| --------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `auto`    | If Scale tier is enabled for the project, the system will use scale tier credits until exhausted; if Scale tier is not enabled for the project, requests will be processed using the default service tier, which has a lower uptime SLA and no latency guarantees |
| `default` | Requests will be processed using the default service tier, which has a lower uptime SLA and no latency guarantees                                                      |
| `flex`    | Requests will be processed using the Flex Processing service tier. Learn more in the official documentation                                                            |

When this parameter is not set, the default behavior is `auto`.

When this parameter is set, the response body will include the `service_tier` used.

#### store

**Type**: boolean or null  
**Required**: No  
**Default**: true

Whether to store the generated model response for later retrieval via the API.

#### stream

**Type**: boolean or null  
**Required**: No  
**Default**: false

If set to true, model response data will be streamed to the client using server-sent events as it is generated.

#### temperature

**Type**: number or null  
**Required**: No  
**Default**: 1

The sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this value or `top_p`, but not both.

#### text

**Type**: object  
**Required**: No

Configuration options for the model's text response. Can be plain text or structured JSON data.

| Property | Type   | Required | Description                      |
| -------- | ------ | -------- | -------------------------------- |
| format   | object | No       | Specifies the format the model must output |

Configure `{ "type": "json_schema" }` to enable structured output, ensuring the model will match the JSON schema you provide. See the structured output guide for more information.

The default format is `{ "type": "text" }`, with no other options.

**Not recommended for gpt-4o and newer models**:
Set to `{ "type": "json_object" }` to enable an older JSON mode, ensuring the model generates a message that is valid JSON. For supported models, `json_schema` is preferred.

##### Text Format Types

###### Text

| Property | Type   | Required | Description                              |
| -------- | ------ | -------- | ---------------------------------------- |
| type     | string | Yes      | The defined response format type. Always `text` |

###### JSON Schema

| Property    | Type         | Required | Description                                                                                                                                               |
| ----------- | ------------ | -------- | --------------------------------------------------------------------------------------------------------------------------------------------------------- |
| name        | string       | Yes      | The name of the response format. Must contain a-z, A-Z, 0-9, or include underscores and hyphens, with a maximum length of 64 |
| schema      | object       | Yes      | The schema for the response format, described as a JSON Schema object                                                                                     |
| type        | string       | Yes      | The defined response format type. Always `json_schema`                                                                                                    |
| description | string       | No       | A description of the response format's purpose, which the model uses to determine how to respond in that format                                           |
| strict      | boolean or null | No       | Whether to enable strict mode adherence when generating output. Defaults to `false`. If set to `true`, the model will always adhere to the exact schema defined in the schema field. Only a subset of JSON Schema is supported in strict mode |

###### JSON Object

| Property | Type   | Required | Description                                     |
| -------- | ------ | -------- | ----------------------------------------------- |
| type     | string | Yes      | The defined response format type. Always `json_object` |

Note: The model will not generate JSON if it is not instructed to do so via a system or user message. For supported models, `json_schema` is recommended.

#### tool_choice

**Type**: string or object  
**Required**: No

How the model chooses which tool (or tools) to use when generating a response. See the `tools` parameter for how to specify the tools the model can call.

##### Possible Types

###### Tool Choice Mode

**Type**: string

Controls whether and which tool the model calls.

| Value      | Description                                            |
| ---------- | ------------------------------------------------------ |
| `none`     | The model will not call any tools, but will generate a message instead |
| `auto`     | The model can choose between generating a message or calling one or more tools |
| `required` | The model must call one or more tools                  |

###### Hosted Tool

**Type**: object

Indicates that the model should use a built-in tool to generate a response.

| Property | Type   | Required | Description                                                                                              |
| -------- | ------ | -------- | -------------------------------------------------------------------------------------------------------- |
| type     | string | Yes      | The type of hosted tool the model should use. Allowed values are: `file_search`, `web_search_preview`, `computer_use_preview` |

###### Function Tool

**Type**: object

Use this option to force the model to call a specific function.

| Property | Type   | Required | Description                                |
| -------- | ------ | -------- | ------------------------------------------ |
| name     | string | Yes      | The name of the function to call           |
| type     | string | Yes      | For function calls, the type is always `function` |

#### tools

**Type**: array  
**Required**: No

An array of tools the model may call when generating a response. You can specify which tool to use by setting the `tool_choice` parameter.

The two categories of tools you can provide to the model are:

-   **Built-in tools**: Tools provided by OpenAI that extend the model's capabilities, such as web search or file search.
-   **Function calling (custom tools)**: Functions defined by you that enable the model to call your own code.

##### File Search Tool

**Type**: object

A tool that searches for relevant content in uploaded files.

| Property         | Type   | Required | Description                                          |
| ---------------- | ------ | -------- | ---------------------------------------------------- |
| type             | string | Yes      | The type of the file search tool, always `file_search` |
| vector_store_ids | array  | Yes      | A list of vector store IDs to search                 |
| filters          | object | No       | Filters to apply                                     |
| max_num_results  | integer | No       | The maximum number of results to return. This number should be between 1 and 50 (inclusive) |
| ranking_options  | object | No       | Search ranking options                               |

###### Filter Types

**Comparison Filter**

| Property | Type               | Required | Description                                                                                                                                                                       |
| -------- | ------------------ | -------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| key      | string             | Yes      | The key to compare against the value                                                                                                                                              |
| type     | string             | Yes      | Specifies the comparison operator: `eq`, `ne`, `gt`, `gte`, `lt`, `lte`<br />- eq: equals`<br />`- ne: not equals`<br />`- gt: greater than`<br />`- gte: greater than or equals`<br />`- lt: less than`<br />`- lte: less than or equals |
| value    | string/number/boolean | Yes      | The value to compare against the property key; supports string, number, or boolean types                                                                                    |

**Compound Filter**

| Property | Type   | Required | Description                                                 |
| -------- | ------ | -------- | ----------------------------------------------------------- |
| filters  | array  | Yes      | An array of filters to combine. Items can be comparison filters or compound filters |
| type     | string | Yes      | The type of operation: `and` or `or`                        |

###### Ranking Options

| Property        | Type   | Required | Description                                                                                              |
| --------------- | ------ | -------- | -------------------------------------------------------------------------------------------------------- |
| ranker          | string | No       | The ranker used for file search                                                                          |
| score_threshold | number | No       | The score threshold for file search, a number between 0 and 1. A number closer to 1 will attempt to return only the most relevant results, but may return fewer results |

##### Function Tool

**Type**: object

Defines a function from your own code that the model can optionally call.

| Property    | Type   | Required | Description                                   |
| ----------- | ------ | -------- | --------------------------------------------- |
| type        | string | Yes      | The type of the function tool, always `function` |
| name        | string | Yes      | The name of the function to call              |
| parameters  | object | Yes      | A JSON schema object describing the function's parameters |
| strict      | boolean | Yes      | Whether to enforce strict parameter validation. Defaults to `true` |
| description | string | No       | A description of the function. The model uses this to determine whether to call the function |

##### Web Search Tool (Web search preview)

**Type**: object

This tool searches the web for relevant results to respond with.

| Property            | Type   | Required | Description                                                                                     |
| ------------------- | ------ | -------- | ----------------------------------------------------------------------------------------------- |
| type                | string | Yes      | The type of the web search tool. Possible values: `web_search_preview` or `web_search_preview_2025_03_11` |
| search_context_size | string | No       | High-level guidance on the amount of context window space to use for searching. Possible values: `low`, `medium`, `high`. Defaults to `medium` |
| user_location       | object | No       | The user's location                                                                             |
| domains             | array  | No       | A list of domains to restrict the search to                                                     |

###### User Location

| Property | Type   | Required | Description                                             |
| -------- | ------ | -------- | ------------------------------------------------------- |
| type     | string | Yes      | The approximate type of location. Always `approximate`  |
| city     | string | No       | Free-form text input for the user's city, e.g., "San Francisco" |
| country  | string | No       | The user's two-letter ISO country code, e.g., "US"      |
| region   | string | No       | Free-form text input for the user's region, e.g., "California" |
| timezone | string | No       | The user's IANA timezone, e.g., "America/Los_Angeles"   |

##### Computer Use Tool (Computer use preview)

**Type**: object

A tool that controls a virtual computer.

| Property       | Type   | Required | Description                                                |
| -------------- | ------ | -------- | ---------------------------------------------------------- |
| type           | string | Yes      | The type of the computer use tool. Always `computer_use_preview` |
| display_height | integer | Yes      | The height of the computer display                         |
| display_width  | integer | Yes      | The width of the computer display                          |
| environment    | string | Yes      | The type of computer environment to control                |

#### top_p

**Type**: number or null  
**Required**: No  
**Default**: 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this value or `temperature`, but not both.

#### truncation

**Type**: string or null  
**Required**: No  
**Default**: disabled

The truncation strategy for model responses:

| Value      | Description                                                                                                             |
| ---------- | ----------------------------------------------------------------------------------------------------------------------- |
| `auto`     | If the context for this response and the previous response exceeds the model's context window size, the model will truncate the response by removing input items from the middle of the conversation to fit the context window |
| `disabled` | If the model response would exceed the model's context window size, the request will fail with a 400 error              |

#### user

**Type**: string  
**Required**: No

A unique identifier representing the end-user, which can help OpenAI monitor and detect abuse.

## ğŸ“¥ Response

Returns a response object.

### Successful Response

Returns a response object, or a streaming sequence of response objects if the request was streamed.

#### id

-   Type: string
-   Description: The unique identifier for the response

#### object

-   Type: string
-   Description: The object type, with a value of "response"

#### created_at

-   Type: integer
-   Description: Timestamp of when the response was created

#### status

-   Type: string
-   Description: The status of the response, such as "completed", "in_progress", etc.

#### error

-   Type: object or null
-   Description: Contains error information if an error occurred

#### incomplete_details

-   Type: object or null
-   Description: Contains detailed information if the response is incomplete

#### instructions

-   Type: string or null
-   Description: System instructions provided to the model

#### max_output_tokens

-   Type: integer or null
-   Description: Maximum number of output tokens

#### model

-   Type: string
-   Description: The name of the model used

#### output

-   Type: array
-   Description: Contains generated replies and tool calls
-   May contain:
    -   Message object (`type`: "message")
    -   Tool use object (`type`: "tool_use")

#### parallel_tool_calls

-   Type: boolean
-   Description: Whether parallel tool calls are enabled

#### previous_response_id

-   Type: string or null
-   Description: ID of the previous response (for multi-turn conversations)

#### reasoning

-   Type: object
-   Description: Reasoning-related information

#### store

-   Type: boolean
-   Description: Whether to store this response

#### temperature

-   Type: number
-   Description: The sampling temperature used

#### text

-   Type: object
-   Description: Text output format configuration

#### tool_choice

-   Type: string
-   Description: Tool choice strategy

#### tools

-   Type: array
-   Description: List of available tools

#### top_p

-   Type: number
-   Description: Nucleus sampling threshold

#### truncation

-   Type: string
-   Description: Truncation strategy

#### usage

-   Type: object
-   Description: Token usage statistics
-   Properties:
    -   `input_tokens`: Number of tokens used for input
    -   `input_tokens_details`: Input token details
    -   `output_tokens`: Number of tokens used for output
    -   `output_tokens_details`: Output token details
    -   `total_tokens`: Total number of tokens

#### user

-   Type: string or null
-   Description: User identifier

#### metadata

-   Type: object
-   Description: Additional metadata information