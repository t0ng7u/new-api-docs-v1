---
title: OpenAI Chat Completions Format
---

<Callout type="info" title="Official Documentation">
  [OpenAI Chat](https://platform.openai.com/docs/api-reference/chat)
</Callout>

## üìù Introduction

Given a list of messages comprising a conversation, the model will return a response. For related guides, please refer to the OpenAI official website: [Chat Completions](https://platform.openai.com/docs/guides/chat)

## üí° Request Examples

### Basic Text Chat ‚úÖ

```bash
curl https://your-newapi-server-address/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "messages": [
      {
        "role": "developer",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "Hello!"
      }
    ]
  }'
```

**Response Example:**

```json
{
  "id": "chatcmpl-B9MBs8CjcvOU2jLn4n570S5qMJKcT",
  "object": "chat.completion",
  "created": 1741569952,
  "model": "gpt-4.1-2025-04-14",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! How can I help you?",
        "refusal": null,
        "annotations": []
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 19,
    "completion_tokens": 10,
    "total_tokens": 29,
    "prompt_tokens_details": {
      "cached_tokens": 0,
      "audio_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "audio_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "service_tier": "default"
}
```

### Image Analysis Chat ‚úÖ

```bash
curl https://your-newapi-server-address/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "What is in this image?"
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
            }
          }
        ]
      }
    ],
    "max_tokens": 300
  }'
```

**Response Example:**

```json
{
  "id": "chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG",
  "object": "chat.completion",
  "created": 1741570283,
  "model": "gpt-4.1-2025-04-14",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "The image shows a wooden boardwalk winding through lush green grass or a meadow. The sky is blue with a few scattered clouds, creating a peaceful and serene atmosphere for the entire scene. Trees and bushes can be seen in the background.",
        "refusal": null,
        "annotations": []
      },
      "logprobs": null,
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 1117,
    "completion_tokens": 46,
    "total_tokens": 1163,
    "prompt_tokens_details": {
      "cached_tokens": 0,
      "audio_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "audio_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "service_tier": "default",
  "system_fingerprint": "fp_fc9f1d7035"
}
```

### Streaming Response ‚úÖ

```bash
curl https://your-newapi-server-address/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "messages": [
      {
        "role": "developer",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "Hello!"
      }
    ],
    "stream": true
  }'
```

**Streaming Response Example:**

```jsonl
{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"‰Ω†Â•Ω"},"logprobs":null,"finish_reason":null}]}

// ... more data chunks ...

{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
```

### Function Calling ‚úÖ

```bash
curl https://your-newapi-server-address/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "messages": [
      {
        "role": "user",
        "content": "What's the weather like in Boston today?"
      }
    ],
    "tools": [
      {
        "type": "function",
        "function": {
          "name": "get_current_weather",
          "description": "Get the current weather in a given location",
          "parameters": {
            "type": "object",
            "properties": {
              "location": {
                "type": "string",
                "description": "City and state, e.g. San Francisco, CA"
              },
              "unit": {
                "type": "string",
                "enum": ["celsius", "fahrenheit"]
              }
            },
            "required": ["location"]
          }
        }
      }
    ],
    "tool_choice": "auto"
  }'
```

**Response Example:**

```json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1699896916,
  "model": "gpt-4o-mini",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": null,
        "tool_calls": [
          {
            "id": "call_abc123",
            "type": "function",
            "function": {
              "name": "get_current_weather",
              "arguments": "{\n\"location\": \"Boston, MA\"\n}"
            }
          }
        ]
      },
      "logprobs": null,
      "finish_reason": "tool_calls"
    }
  ],
  "usage": {
    "prompt_tokens": 82,
    "completion_tokens": 17,
    "total_tokens": 99,
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  }
}
```

### Logprobs Request ‚úÖ

```bash
curl https://your-newapi-server-address/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $NEWAPI_API_KEY" \
  -d '{
    "model": "gpt-4.1",
    "messages": [
      {
        "role": "user",
        "content": "Hello!"
      }
    ],
    "logprobs": true,
    "top_logprobs": 2
  }'
```

**Response Example:**

```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "created": 1702685778,
  "model": "gpt-4o-mini",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! How can I help you?"
      },
      "logprobs": {
        "content": [
          {
            "token": "Hello",
            "logprob": -0.31725305,
            "bytes": [72, 101, 108, 108, 111],
            "top_logprobs": [
              {
                "token": "Hello",
                "logprob": -0.31725305,
                "bytes": [72, 101, 108, 108, 111]
              },
              {
                "token": "Hi",
                "logprob": -1.3190403,
                "bytes": [72, 105]
              }
            ]
          },
          {
            "token": "!",
            "logprob": -0.02380986,
            "bytes": [33],
            "top_logprobs": [
              {
                "token": "!",
                "logprob": -0.02380986,
                "bytes": [33]
              },
              {
                "token": " there",
                "logprob": -3.787621,
                "bytes": [32, 116, 104, 101, 114, 101]
              }
            ]
          },
          {
            "token": " How",
            "logprob": -0.000054669687,
            "bytes": [32, 72, 111, 119],
            "top_logprobs": [
              {
                "token": " How",
                "logprob": -0.000054669687,
                "bytes": [32, 72, 111, 119]
              },
              {
                "token": "`<|end|>`",
                "logprob": -10.953937,
                "bytes": null
              }
            ]
          },
          {
            "token": " can",
            "logprob": -0.015801601,
            "bytes": [32, 99, 97, 110],
            "top_logprobs": [
              {
                "token": " can",
                "logprob": -0.015801601,
                "bytes": [32, 99, 97, 110]
              },
              {
                "token": " may",
                "logprob": -4.161023,
                "bytes": [32, 109, 97, 121]
              }
            ]
          },
          {
            "token": " I",
            "logprob": -3.7697225e-6,
            "bytes": [32, 73],
            "top_logprobs": [
              {
                "token": " I",
                "logprob": -3.7697225e-6,
                "bytes": [32, 73]
              },
              {
                "token": " assist",
                "logprob": -13.596657,
                "bytes": [32, 97, 115, 115, 105, 115, 116]
              }
            ]
          },
          {
            "token": " assist",
            "logprob": -0.04571125,
            "bytes": [32, 97, 115, 115, 105, 115, 116],
            "top_logprobs": [
              {
                "token": " assist",
                "logprob": -0.04571125,
                "bytes": [32, 97, 115, 115, 105, 115, 116]
              },
              {
                "token": " help",
                "logprob": -3.1089056,
                "bytes": [32, 104, 101, 108, 112]
              }
            ]
          },
          {
            "token": " you",
            "logprob": -5.4385737e-6,
            "bytes": [32, 121, 111, 117],
            "top_logprobs": [
              {
                "token": " you",
                "logprob": -5.4385737e-6,
                "bytes": [32, 121, 111, 117]
              },
              {
                "token": " today",
                "logprob": -12.807695,
                "bytes": [32, 116, 111, 100, 97, 121]
              }
            ]
          },
          {
            "token": " today",
            "logprob": -0.0040071653,
            "bytes": [32, 116, 111, 100, 97, 121],
            "top_logprobs": [
              {
                "token": " today",
                "logprob": -0.0040071653,
                "bytes": [32, 116, 111, 100, 97, 121]
              },
              {
                "token": "?",
                "logprob": -5.5247097,
                "bytes": [63]
              }
            ]
          },
          {
            "token": "?",
            "logprob": -0.0008108172,
            "bytes": [63],
            "top_logprobs": [
              {
                "token": "?",
                "logprob": -0.0008108172,
                "bytes": [63]
              },
              {
                "token": "?\n",
                "logprob": -7.184561,
                "bytes": [63, 10]
              }
            ]
          }
        ]
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 9,
    "completion_tokens": 9,
    "total_tokens": 18,
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    }
  },
  "system_fingerprint": null
}
```

## üìÆ Request

### Endpoint

```
POST /v1/chat/completions
```

Creates a model response for the given chat conversation. For more details, refer to the text generation, vision, and audio guides.

### Authentication Method

Include the following in the request header for API key authentication:

```
Authorization: Bearer $NEWAPI_API_KEY
```

Where `$NEWAPI_API_KEY` is your API key. You can find or generate your API key on the API Keys page of the OpenAI platform.

### Request Body Parameters

#### `messages`

- Type: Array
- Required: Yes

A list of messages comprising the conversation so far. Different message types (forms) are supported depending on the model used, such as text, image, and audio.

| Message Type              | Description                                                                                                                              | Available for       |
| ------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- | ------------------- |
| **Developer message**     | Instructions provided by the developer that the model should follow, regardless of what the user sends. In o1 models and newer, developer messages replace previous system messages. | All message types   |
| **System message**        | Instructions provided by the developer that the model should follow, regardless of what the user sends. In o1 models and newer, please use developer messages instead. | All message types   |
| **User message**          | Messages sent by the end-user, containing prompts or additional context information.                                                     | All message types   |
| **Assistant message**     | Messages sent by the model in response to user messages.                                                                                 | All message types   |
| **Tool message**          | The content of the tool message.                                                                                                         | All message types   |
| **Function message**      | Deprecated.                                                                                                                              | All message types   |

**Developer message attributes:**

| Attribute | Type          | Required | Description                                                                                                |
| --------- | ------------- | -------- | ---------------------------------------------------------------------------------------------------------- |
| `role`    | String        | Yes      | The role of the message author, which is `developer` here.                                                 |
| `content` | String or Array | Yes      | The content of the developer message. Can be text content (string) or an array of content parts.           |
| `name`    | String        | No       | An optional name for the participant. Provides information to the model to differentiate between participants with the same role. |

**System message attributes:**

| Attribute | Type          | Required | Description                                                                                                |
| --------- | ------------- | -------- | ---------------------------------------------------------------------------------------------------------- |
| `role`    | String        | Yes      | The role of the message author, which is `system` here.                                                    |
| `content` | String or Array | Yes      | The content of the system message. Can be text content (string) or an array of content parts.              |
| `name`    | String        | No       | An optional name for the participant. Provides information to the model to differentiate between participants with the same role. |

**User message attributes:**

| Attribute | Type          | Required | Description                                                                                                |
| --------- | ------------- | -------- | ---------------------------------------------------------------------------------------------------------- |
| `role`    | String        | Yes      | The role of the message author, which is `user` here.                                                      |
| `content` | String or Array | Yes      | The content of the user message. Can be text content (string) or an array of content parts.                |
| `name`    | String        | No       | An optional name for the participant. Provides information to the model to differentiate between participants with the same role. |

**Content part types:**

| Content Part Type     | Description                                     | Available for   |
| --------------------- | ----------------------------------------------- | --------------- |
| **Text content part** | Text input.                                     | All message types |
| **Image content part** | Image input.                                    | User messages   |
| **Audio content part** | Audio input.                                    | User messages   |
| **File content part** | File input, used for text generation.           | User messages   |
| **Refusal content part** | A refusal message generated by the model.       | Assistant messages |

**Text content part attributes:**

| Attribute | Type   | Required | Description              |
| --------- | ------ | -------- | ------------------------ |
| `text`    | String | Yes      | The text content.        |
| `type`    | String | Yes      | The type of the content part. |

**Image content part attributes:**

| Attribute   | Type   | Required | Description                                     |
| ----------- | ------ | -------- | ----------------------------------------------- |
| `image_url` | Object | Yes      | Contains the image URL or base64 encoded image data. |
| `type`      | String | Yes      | The type of the content part.                   |

**Image URL object attributes:**

| Attribute | Type   | Required | Description                                       |
| --------- | ------ | -------- | ------------------------------------------------- |
| `url`     | String | Yes      | The URL or base64 encoded image data of the image. |
| `detail`  | String | No       | Specifies the detail level of the image. Defaults to `auto`. |

**Audio content part attributes:**

| Attribute     | Type   | Required | Description                                    |
| ------------- | ------ | -------- | ---------------------------------------------- |
| `input_audio` | Object | Yes      | An object containing audio data.               |
| `type`        | String | Yes      | The type of the content part. Always `input_audio`. |

**Audio input object attributes:**

| Attribute | Type   | Required | Description                                          |
| --------- | ------ | -------- | ---------------------------------------------------- |
| `data`    | String | Yes      | The base64 encoded audio data.                       |
| `format`  | String | Yes      | The format of the encoded audio data. Currently supports "wav" and "mp3". |

**File content part attributes:**

| Attribute | Type   | Required | Description                                |
| --------- | ------ | -------- | ------------------------------------------ |
| `file`    | Object | Yes      | An object containing file data.            |
| `type`    | String | Yes      | The type of the content part. Always `file`. |

**File object attributes:**

| Attribute   | Type   | Required | Description                                                              |
| ----------- | ------ | -------- | ------------------------------------------------------------------------ |
| `file_data` | String | No       | Base64 encoded file data, used to pass the file as a string to the model. |
| `file_id`   | String | No       | The ID of the uploaded file, used as input.                              |
| `filename`  | String | No       | The filename, used to pass the file as a string to the model.            |

**Assistant message attributes:**

| Attribute       | Type          | Required | Description                                                                                                |
| --------------- | ------------- | -------- | ---------------------------------------------------------------------------------------------------------- |
| `role`          | String        | Yes      | The role of the message author, which is `assistant` here.                                                 |
| `content`       | String or Array | No       | The content of the assistant message. Required unless `tool_calls` or `function_call` is specified.        |
| `name`          | String        | No       | An optional name for the participant. Provides information to the model to differentiate between participants with the same role. |
| `audio`         | Object or null | No       | Data about the model's previous audio response.                                                            |
| `function_call` | Object or null | No       | Deprecated, replaced by `tool_calls`. The name and arguments of a function that should be called, as generated by the model. |
| `tool_calls`    | Array         | No       | The tool calls generated by the model, such as function calls.                                             |
| `refusal`       | String or null | No       | The assistant's refusal message.                                                                           |

**Tool message attributes:**

| Attribute      | Type          | Required | Description                                |
| -------------- | ------------- | -------- | ------------------------------------------ |
| `role`         | String        | Yes      | The role of the message author, which is `tool` here. |
| `content`      | String or Array | Yes      | The content of the tool message.           |
| `tool_call_id` | String        | Yes      | The tool call this message is responding to. |

**Function message attributes: (Deprecated)**

| Attribute | Type          | Required | Description                                |
| --------- | ------------- | -------- | ------------------------------------------ |
| `role`    | String        | Yes      | The role of the message author, which is `function` here. |
| `content` | String or null | Yes      | The content of the function message.       |
| `name`    | String        | Yes      | The name of the function to call.          |

#### `model`

- Type: String
- Required: Yes

ID of the model to use. See the model endpoint compatibility table for details on which models are available for the Chat API.

#### `store`

- Type: Boolean or null
- Required: No
- Default: false

Whether to store the output of this chat completion request for use in our model distillation or evaluation products.

#### `reasoning_effort`

- Type: String or null
- Required: No
- Default: medium
- Only for o-series models

Constrains the reasoning effort of reasoning models. Currently supported values are `low`, `medium`, and `high`. Reducing reasoning effort can speed up responses and reduce the number of tokens used for reasoning in the response.

#### `metadata`

- Type: Map
- Required: No

A set of 16 key-value pairs that can be attached to an object. This is useful for storing additional information about the object in a structured format and can be queried via the API or dashboard.

Keys are strings up to 64 characters in length. Values are strings up to 512 characters in length.

#### `modalities`

- Type: Array or null
- Required: No

The types of outputs you want the model to generate for this request. Most models can generate text, which is the default:
["text"]

The model can also be used to generate audio. To request that the model generate both text and audio responses, you can use:
["text", "audio"]

#### `prediction`

- Type: Object
- Required: No

Configuration for speculative output, which can significantly improve response times when most of the model's response is known in advance. This is most common when you are only making minor changes to a file.

**Possible types:**

| Type             | Description                                                                                                |
| ---------------- | ---------------------------------------------------------------------------------------------------------- |
| **Static content** | Static speculative output content, such as the content of a text file being regenerated with minor changes. |

**Static content attributes:**

| Attribute | Type          | Required | Description                                                                                                |
| --------- | ------------- | -------- | ---------------------------------------------------------------------------------------------------------- |
| `content` | String or Array | Yes      | The content that the generated model response should match. If the generated tokens match this content, the entire model response can be returned faster. |
| `type`    | String        | Yes      | The type of speculative content to provide. The current type is always `content`.                          |

**Content possible types:**

1.  **Text content (string)** - The content to use for speculative output. This is typically the text of a file you are regenerating with minor changes.

2.  **Array of content parts (array)** - An array of content parts with defined types. Supported options vary depending on the model used to generate the response. Can include text input.

**Content part array attributes:**

| Attribute | Type   | Required | Description              |
| --------- | ------ | -------- | ------------------------ |
| `text`    | String | Yes      | The text content.        |
| `type`    | String | Yes      | The type of the content part. |

#### `audio`

- Type: Object or null
- Required: No

Parameters for audio output. Required when requesting audio output using `modalities: ["audio"]`.

| Attribute | Type   | Required | Description                                                                                                |
| --------- | ------ | -------- | ---------------------------------------------------------------------------------------------------------- |
| `format`  | String | Yes      | Specifies the output audio format. Must be one of the following: wav, mp3, flac, opus, or pcm16.           |
| `voice`   | String | Yes      | The voice the model should use for its response. Supported voices are: alloy, ash, ballad, coral, echo, fable, nova, onyx, sage, and shimmer. |

#### `temperature`

- Type: Number or null
- Required: No
- Default: 1

What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` but not both.

#### `top_p`

- Type: Number or null
- Required: No
- Default: 1

An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or `temperature` but not both.

#### `n`

- Type: Integer or null
- Required: No
- Default: 1

How many chat completion choices to generate for each input message. Note that you will be charged based on the number of tokens generated across all choices. Keep `n` at 1 to minimize costs.

#### `stop`

- Type: String/Array/null
- Required: No
- Default: null
- Not supported by the latest inference models and .o3, o4-mini

Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.

#### `max_tokens`

- Type: Integer or null
- Required: No

The maximum number of tokens that can be generated in the chat completion. This value can be used to control the cost of text generated via the API.

This value is now deprecated in favor of `max_completion_tokens` and is not compatible with `o1` series models.

#### `max_completion_tokens`

- Type: Integer or null
- Required: No

The upper bound on the number of tokens that can be generated in the completion, including both visible output tokens and reasoning tokens.

#### `presence_penalty`

- Type: Number or null
- Required: No
- Default: 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

#### `frequency_penalty`

- Type: Number or null
- Required: No
- Default: 0

Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

#### `logit_bias`

- Type: Map
- Required: No
- Default: null

Modifies the likelihood of specified tokens appearing in the completion.

Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase the likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

#### `logprobs`

- Type: Boolean or null
- Required: No
- Default: false

Whether to return the log probabilities of the output tokens. If true, returns the log probabilities of each output token in `message.content`.

#### `user`

- Type: String
- Required: No

A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).

#### `service_tier`

- Type: String or null
- Required: No
- Default: auto

Specifies the latency tier used to process the request. This parameter is relevant for customers subscribed to scale tier services:

- If set to 'auto' and the project has Scale tier enabled, the system will use scale tier credits until exhausted
- If set to 'auto' and the project does not have Scale tier enabled, the request will be processed using the default service tier, which has a lower uptime SLA and no latency guarantees
- If set to 'default', the request will be processed using the default service tier, which has a lower uptime SLA and no latency guarantees
- If set to 'flex', the request will be processed using the Flex Processing service tier. Refer to the documentation for details.
- When not set, the default behavior is 'auto'
- When this parameter is set, the response body will include the `service_tier` used

#### `stream_options`

- Type: Object or null
- Required: No
- Default: null

Options for streaming responses. Only used when `stream: true` is set.

**Possible attributes:**

| Attribute       | Type    | Required | Description