---
title: Anthropic Conversation Format (Messages)
---

<Callout type="info" title="Official Documentation">
  - [Anthropic Messages](https://docs.anthropic.com/en/api/messages) -
  [Anthropic Streaming
  Messages](https://docs.anthropic.com/en/api/messages-streaming)
</Callout>

## ðŸ“ Introduction

Given a list of structured input messages containing text and/or image content, the model will generate the next message in the conversation. The Messages API can be used for single queries or stateless multi-turn conversations.

## ðŸ’¡ Request Examples

### Basic Text Conversation âœ…

```bash
curl https://ä½ çš„newapiæœåŠ¡å™¨åœ°å€/v1/messages \
     --header "anthropic-version: 2023-06-01" \
     --header "content-type: application/json" \
     --header "x-api-key: $NEWAPI_API_KEY" \
     --data \
'{
    "model": "claude-3-5-sonnet-20241022",
    "max_tokens": 1024,
    "messages": [
        {"role": "user", "content": "Hello, world"}
    ]
}'
```

**Response Example:**

```json
{
  "content": [
    {
      "text": "Hi! My name is Claude.",
      "type": "text"
    }
  ],
  "id": "msg_013Zva2CMHLNnXjNJKqJ2EF",
  "model": "claude-3-5-sonnet-20241022",
  "role": "assistant",
  "stop_reason": "end_turn",
  "stop_sequence": null,
  "type": "message",
  "usage": {
    "input_tokens": 2095,
    "output_tokens": 503
  }
}
```

### Image Analysis Conversation âœ…

```bash
curl https://ä½ çš„newapiæœåŠ¡å™¨åœ°å€/v1/messages \
     --header "anthropic-version: 2023-06-01" \
     --header "content-type: application/json" \
     --header "x-api-key: $NEWAPI_API_KEY" \
     --data \
'{
    "model": "claude-3-5-sonnet-20241022",
    "messages": [
        {
            "role": "user",
            "content": [
                {
                    "type": "image",
                    "source": {
                        "type": "base64",
                        "media_type": "image/jpeg",
                        "data": "/9j/4AAQSkZJRg..."
                    }
                },
                {
                    "type": "text",
                    "text": "What is in this picture?"
                }
            ]
        }
    ]
}'
```

**Response Example:**

```json
{
  "content": [
    {
      "text": "è¿™å¼ å›¾ç‰‡æ˜¾ç¤ºäº†ä¸€åªæ©™è‰²çš„çŒ«å’ªæ­£åœ¨çª—å°ä¸Šæ™’å¤ªé˜³ã€‚çŒ«å’ªçœ‹èµ·æ¥å¾ˆæ”¾æ¾ï¼Œçœ¯ç€çœ¼ç›äº«å—é˜³å…‰ã€‚çª—å¤–å¯ä»¥çœ‹åˆ°ä¸€äº›ç»¿è‰²çš„æ¤ç‰©ã€‚",
      "type": "text"
    }
  ],
  "id": "msg_013Zva2CMHLNnXjNJKqJ2EF",
  "model": "claude-3-5-sonnet-20241022",
  "role": "assistant",
  "stop_reason": "end_turn",
  "stop_sequence": null,
  "type": "message",
  "usage": {
    "input_tokens": 3050,
    "output_tokens": 892
  }
}
```

### Tool Calling âœ…

```bash
curl https://ä½ çš„newapiæœåŠ¡å™¨åœ°å€/v1/messages \
     --header "anthropic-version: 2023-06-01" \
     --header "content-type: application/json" \
     --header "x-api-key: $NEWAPI_API_KEY" \
     --data \
'{
    "model": "claude-3-5-sonnet-20241022",
    "messages": [
        {
            "role": "user",
            "content": "What\'s the weather like in Beijing today?"
        }
    ],
    "tools": [
        {
            "name": "get_weather",
            "description": "Get the current weather for the specified location",
            "input_schema": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "City name, e.g., Beijing"
                    }
                },
                "required": ["location"]
            }
        }
    ]
}'
```

**Response Example:**

```json
{
  "content": [
    {
      "type": "tool_use",
      "id": "toolu_01D7FLrfh4GYq7yT1ULFeyMV",
      "name": "get_weather",
      "input": { "location": "åŒ—äº¬" }
    }
  ],
  "id": "msg_013Zva2CMHLNnXjNJKqJ2EF",
  "model": "claude-3-5-sonnet-20241022",
  "role": "assistant",
  "stop_reason": "tool_use",
  "stop_sequence": null,
  "type": "message",
  "usage": {
    "input_tokens": 2156,
    "output_tokens": 468
  }
}
```

### Streaming Response âœ…

```bash
curl https://ä½ çš„newapiæœåŠ¡å™¨åœ°å€/v1/messages \
     --header "anthropic-version: 2023-06-01" \
     --header "content-type: application/json" \
     --header "x-api-key: $NEWAPI_API_KEY" \
     --data \
'{
    "model": "claude-3-5-sonnet-20241022",
    "messages": [
        {
            "role": "user",
            "content": "Tell a story"
        }
    ],
    "stream": true
}'
```

**Response Example:**

```json
{
  "type": "message_start",
  "message": {
    "id": "msg_013Zva2CMHLNnXjNJKqJ2EF",
    "model": "claude-3-5-sonnet-20241022",
    "role": "assistant",
    "type": "message"
  }
}
{
  "type": "content_block_start",
  "index": 0,
  "content_block": {
    "type": "text"
  }
}
{
  "type": "content_block_delta",
  "index": 0,
  "delta": {
    "text": "ä»Žå‰"
  }
}
{
  "type": "content_block_delta",
  "index": 0,
  "delta": {
    "text": "æœ‰ä¸€åª"
  }
}
{
  "type": "content_block_delta",
  "index": 0,
  "delta": {
    "text": "å°å…”å­..."
  }
}
{
  "type": "content_block_stop",
  "index": 0
}
{
  "type": "message_delta",
  "delta": {
    "stop_reason": "end_turn",
    "usage": {
      "input_tokens": 2045,
      "output_tokens": 628
    }
  }
}
{
  "type": "message_stop"
}
```

## ðŸ“® Request

### Endpoint

```
POST /v1/messages
```

### Authentication Method

Include the following in the request header for API key authentication:

```
x-api-key: $NEWAPI_API_KEY
```

Where `$NEWAPI_API_KEY` is your API key. You can obtain your API key through the console, and each key is limited to one workspace.

### Request Header Parameters

#### `anthropic-beta`

- Type: string
- Required: No

Specifies the beta version to use, supports a comma-separated list like `beta1,beta2`, or specifying the header multiple times.

#### `anthropic-version`

- Type: string
- Required: Yes

Specifies the API version to use.

### Request Body Parameters

#### `max_tokens`

- Type: integer
- Required: Yes

The maximum number of tokens to generate. Different models have different limits, see model documentation for details. Range `x > 1`.

#### `messages`

- Type: array of objects
- Required: Yes

A list of input messages. Models are trained to alternate between user and assistant turns in a conversation. When creating a new message, you can specify previous conversation turns using the messages parameter, and the model will generate the next message in the conversation. Consecutive user or assistant messages will be merged into a single turn.

Each message must contain `role` and `content` fields. You can specify a single user role message, or include multiple user and assistant messages. If the last message uses an assistant role, the response content will continue directly from that message, which can be used to constrain the model's response.

**Single User Message Example:**

```json
[{ "role": "user", "content": "Hello, Claude" }]
```

**Multi-turn Conversation Example:**

```json
[
  { "role": "user", "content": "Hello." },
  { "role": "assistant", "content": "Hello! I'm Claude. How can I help you?" },
  { "role": "user", "content": "Please explain what LLM is in simple terms?" }
]
```

**Partially Filled Response Example:**

```json
[
  {
    "role": "user",
    "content": "What is the Greek name for the sun? (A) Sol (B) Helios (C) Sun"
  },
  { "role": "assistant", "content": "The correct answer is (" }
]
```

The content of each message can be a string or an array of content blocks. Using a string is equivalent to a shorthand for an array of "text" type content blocks. The following two syntaxes are equivalent:

```json
{ "role": "user", "content": "Hello, Claude" }
```

```json
{
  "role": "user",
  "content": [{ "type": "text", "text": "Hello, Claude" }]
}
```

Starting with Claude 3 models, you can also send image content blocks:

```json
{
  "role": "user",
  "content": [
    {
      "type": "image",
      "source": {
        "type": "base64",
        "media_type": "image/jpeg",
        "data": "/9j/4AAQSkZJRg..."
      }
    },
    {
      "type": "text",
      "text": "What is in this picture?"
    }
  ]
}
```

> Currently supported image formats include: base64, image/jpeg, image/png, image/gif, and image/webp.

##### `messages.role`

- Type: enum string
- Required: Yes
- Possible values: user, assistant

Note: There is no "system" role in the Messages API. If a system prompt is needed, please use the top-level system parameter.

##### `messages.content`

- Type: string or array of objects
- Required: Yes

Message content can be one of the following types:

###### Text Content (Text)

```json
{
  "type": "text", // Required, enum value: "text"
  "text": "Hello, Claude", // Required, minimum length: 1
  "cache_control": {
    "type": "ephemeral" // Optional, enum value: "ephemeral"
  }
}
```

###### Image Content (Image)

```json
{
  "type": "image", // Required, enum value: "image"
  "source": {
    // Required
    "type": "base64", // Required, enum value: "base64"
    "media_type": "image/jpeg", // Required, supports: image/jpeg, image/png, image/gif, image/webp
    "data": "/9j/4AAQSkZJRg..." // Required, base64 encoded image data
  },
  "cache_control": {
    "type": "ephemeral" // Optional, enum value: "ephemeral"
  }
}
```

###### Tool Use (Tool Use)

```json
{
  "type": "tool_use", // Required, enum value: "tool_use", default value
  "id": "toolu_xyz...", // Required, unique identifier for tool use
  "name": "get_weather", // Required, tool name, minimum length: 1
  "input": {
    // Required, input parameters object for the tool
    // Tool input parameters, specific format defined by the tool's input_schema
  },
  "cache_control": {
    "type": "ephemeral" // Optional, enum value: "ephemeral"
  }
}
```

###### Tool Result (Tool Result)

```json
{
  "type": "tool_result", // Required, enum value: "tool_result"
  "tool_use_id": "toolu_xyz...", // Required
  "content": "Result content", // Required, can be a string or an array of content blocks
  "is_error": false, // Optional, boolean
  "cache_control": {
    "type": "ephemeral" // Optional, enum value: "ephemeral"
  }
}
```

When content is an array of content blocks, each content block can be text or image:

```json
{
  "type": "tool_result",
  "tool_use_id": "toolu_xyz...",
  "content": [
    {
      "type": "text", // Required, enum value: "text"
      "text": "Analysis result", // Required, minimum length: 1
      "cache_control": {
        "type": "ephemeral" // Optional, enum value: "ephemeral"
      }
    },
    {
      "type": "image", // Required, enum value: "image"
      "source": {
        // Required
        "type": "base64", // Required, enum value: "base64"
        "media_type": "image/jpeg",
        "data": "..."
      },
      "cache_control": {
        "type": "ephemeral"
      }
    }
  ]
}
```

###### Document (Document)

```json
{
  "type": "document", // Required, enum value: "document"
  "source": {
    // Required
    // Document source data
  },
  "cache_control": {
    "type": "ephemeral" // Optional, enum value: "ephemeral"
  }
}
```

Note:

1.  Each type can include an optional `cache_control` field to control content caching behavior.
2.  The minimum length for text content is 1.
3.  The `type` field for all types is a required enum string.
4.  The `content` field for tool results supports strings or arrays of content blocks containing text/images.

#### `model`

- Type: string
- Required: Yes

The name of the model to use, see model documentation for details. Range `1 - 256` characters.

#### `metadata`

- Type: object
- Required: No

An object describing request metadata. Includes the following optional fields:

-   `user_id`: An external identifier for the user associated with the request. Should be a UUID, hash, or other opaque identifier. Do not include any identifying information such as names, email addresses, or phone numbers. Maximum length: 256.

#### `stop_sequences`

- Type: array of strings
- Required: No

Custom text sequences that stop generation.

#### `stream`

- Type: boolean
- Required: No

Whether to use Server-Sent Events (SSE) to incrementally return response content.

#### `system`

- Type: string
- Required: No

A system prompt that provides background and instructions to Claude. This is a way to give the model context and a specific goal or role. Note that this is different from the `role` in messages; there is no "system" role in the Messages API.

#### `temperature`

- Type: number
- Required: No
- Default value: 1.0

Controls the randomness of generation, 0.0 - 1.0. Range `0 < x < 1`. It is recommended to use values close to 0.0 for analytical/multiple-choice tasks and values close to 1.0 for creative and generative tasks.

Note: Even if temperature is set to 0.0, the results will not be completely deterministic.

#### ðŸ†• `thinking`

- Type: object
- Required: No

Configures Claude's extended thinking feature. When enabled, responses will include content blocks that show Claude's thought process before giving the final answer. Requires a budget of at least 1,024 tokens and counts towards your `max_tokens` limit.

Can be set to one of two modes:

##### 1. Enabled Mode

```json
{
  "type": "enabled",
  "budget_tokens": 2048
}
```

-   `type`: Required, enum value: "enabled"
-   `budget_tokens`: Required, integer. Determines the number of tokens Claude can use for its internal reasoning process. A larger budget allows the model to perform deeper analysis on complex problems, improving response quality. Must be â‰¥1024 and less than `max_tokens`. Range `x > 1024`.

##### 2. Disabled Mode

```json
{
  "type": "disabled"
}
```

-   `type`: Required, enum value: "disabled"

#### `tool_choice`

- Type: object
- Required: No

Controls how the model uses the provided tools. Can be one of three types:

##### 1. Auto Mode (Automatic Selection)

```json
{
  "type": "auto", // Required, enum value: "auto"
  "disable_parallel_tool_use": false // Optional, default false. If true, the model will use at most one tool.
}
```

##### 2. Any Mode (Any Tool)

```json
{
  "type": "any", // Required, enum value: "any"
  "disable_parallel_tool_use": false // Optional, default false. If true, the model will use exactly one tool.
}
```

##### 3. Tool Mode (Specific Tool)

```json
{
  "type": "tool", // Required, enum value: "tool"
  "name": "get_weather", // Required, specifies the name of the tool to use.
  "disable_parallel_tool_use": false // Optional, default false. If true, the model will use exactly one tool.
}
```

Note:

1.  Auto Mode: The model can decide whether to use a tool on its own.
2.  Any Mode: The model must use a tool, but can choose any available tool.
3.  Tool Mode: The model must use the specified tool.

#### `tools`

- Type: array of objects
- Required: No

Defines the tools the model may use. Tools can be custom tools or built-in tool types:

##### 1. Custom Tool (Tool)

Each custom tool definition includes:

-   `type`: Optional, enum value: "custom"
-   `name`: Tool name, required, 1-64 characters
-   `description`: Tool description, recommended to be as detailed as possible
-   `input_schema`: JSON Schema definition for tool input, required
-   `cache_control`: Cache control, optional, type is "ephemeral"

Example:

```json
[
  {
    "type": "custom",
    "name": "get_weather",
    "description": "Get the current weather for the specified location",
    "input_schema": {
      "type": "object",
      "properties": {
        "location": {
          "type": "string",
          "description": "City name, e.g., Beijing"
        }
      },
      "required": ["location"]
    }
  }
]
```

##### 2. Computer Tool (ComputerUseTool)

```json
{
  "type": "computer_20241022", // Required
  "name": "computer", // Required, enum value: "computer"
  "display_width_px": 1024, // Required, display width (pixels)
  "display_height_px": 768, // Required, display height (pixels)
  "display_number": 0, // Optional, X11 display number
  "cache_control": {
    "type": "ephemeral" // Optional
  }
}
```

##### 3. Bash Tool (BashTool)

```json
{
  "type": "bash_20241022", // Required
  "name": "bash", // Required, enum value: "bash"
  "cache_control": {
    "type": "ephemeral" // Optional
  }
}
```

##### 4. Text Editor Tool (TextEditor)

```json
{
  "type": "text_editor_20241022", // Required
  "name": "str_replace_editor", // Required, enum value: "str_replace_editor"
  "cache_control": {
    "type": "ephemeral" // Optional
  }
}
```

When the model uses a tool, it returns a `tool_use` content block:

```json
[
  {
    "type": "tool_use",
    "id": "toolu_01D7FLrfh4GYq7yT1ULFeyMV",
    "name": "get_weather",
    "input": { "location": "åŒ—äº¬" }
  }
]
```

You can execute the tool and return the result via a `tool_result` content block:

```json
[
  {
    "type": "tool_result",
    "tool_use_id": "toolu_01D7FLrfh4GYq7yT1ULFeyMV",
    "content": "Current weather in Beijing is clear, temperature 25Â°C"
  }
]
```

#### `top_k`

- Type: integer
- Required: No
- Range: x > 0

Samples from the top K options for tokens. Used to remove low-probability "long-tail" responses. Recommended for advanced use cases only; usually, only `temperature` needs adjustment.

#### `top_p`

- Type: number
- Required: No
- Range: `0 < x < 1`

Uses nucleus sampling. Computes the cumulative distribution of each subsequent token sorted by probability in descending order, and truncates when the probability specified by `top_p` is reached. It is recommended to adjust either `temperature` or `top_p`, but not both simultaneously.

## ðŸ“¥ Response

### Successful Response

Returns a chat completion object with the following fields:

#### `content`

- Type: array of objects
- Required: Yes

The content generated by the model, consisting of multiple content blocks. Each content block has a `type` that determines its shape. Content blocks can be one of the following types:

##### Text Content Block (Text)

```json
{
  "type": "text", // Required, enum value: "text", default value
  "text": "Hello, I am Claude." // Required, maximum length: 5,000,000, minimum length: 1
}
```

##### Tool Use Content Block (Tool Use)

```json
{
  "type": "tool_use", // Required, enum value: "tool_use", default value
  "id": "toolu_xyz...", // Required, unique identifier for tool use
  "name": "get_weather", // Required, tool name, minimum length: 1
  "input": {
    // Required, input parameters object for the tool
    // Tool input parameters, specific format defined by the tool's input_schema
  }
}
```

Example:

```json
// Text content example
[{"type": "text", "text": "Hello, I am Claude."}]

// Tool use example
[{
  "type": "tool_use",
  "id": "toolu_xyz...",
  "name": "get_weather",
  "input": { "location": "åŒ—äº¬" }
}]

// Mixed content example
[
  {"type": "text", "text": "According to the weather query result:"},
  {
    "type": "tool_use",
    "id": "toolu_xyz...",
    "name": "get_weather",
    "input": { "location": "åŒ—äº¬" }
  }
]
```

If the last message in the request is an assistant role, the response content will continue directly from that message. For example:

```json
// Request
[
  {"role": "user", "content": "What is the Greek name for the sun? (A) Sol (B) Helios (C) Sun"},
  {"role": "assistant", "content": "The correct answer is ("}
]

// Response
[{"type": "text", "text": "B)"}]
```

#### `id`

- Type: string
- Required: Yes

The unique identifier for the response.

#### `model`

- Type: string
- Required: Yes

The name of the model used.

#### `role`

- Type: enum string
- Required: Yes
- Default value: assistant

The conversational role of the generated message, always "assistant".

#### `stop_reason`

- Type: enum string or null
- Required: Yes

The reason for stopping generation, possible values include:

-   `"end_turn"`: The model reached a natural stopping point
-   `"max_tokens"`: The requested `max_tokens` or the model's maximum limit was exceeded
-   `"stop_sequence"`: One of the custom stop sequences was generated
-   `"tool_use"`: The model called one or more tools

In non-streaming mode, this value is always non-null. In streaming mode, it is null in the `message_start` event and non-null otherwise.

#### `stop_sequence`

- Type: string or null
- Required: Yes

The custom stop sequence that was generated. If the model encountered one of the sequences specified in the `stop_sequences` parameter, this field will contain the matching stop sequence. If it stopped for another reason, it will be null.

#### `type`

- Type: enum string
- Required: Yes
- Default value: message
- Possible values: message

The object type, always "message" for Messages.

#### `usage`

- Type: object
- Required: Yes

Usage statistics related to billing and rate limiting. Includes the following fields:

-   `input_tokens`: The number of input tokens used, required, range `x > 0`
-   `output_tokens`: The number of output tokens used, required, range `x > 0`
-   `cache_creation_input_tokens`: The number of input tokens used to create cache entries (if applicable), required, range `x > 0`
-   `cache_read_input_tokens`: The number of input tokens read from cache (if applicable), required, range `x > 0`

Note: Due to internal API transformations and parsing, token counts may not exactly correspond to the actual visible content of the request and response. For example, `output_tokens` will be non-zero even for an empty string response.

### Error Response

When there is an issue with the request, the API will return an error response object with an HTTP status code in the 4XX-5XX range.

#### Common Error Status Codes

-   `401 Unauthorized`: API key invalid or not provided
-   `400 Bad Request`: Invalid request parameters
-   `429 Too Many Requests`: API call limit exceeded
-   `500 Internal Server Error`: Internal server error

Error Response Example:

```json
{
  "error": {
    "type": "invalid_request_error",
    "message": "Invalid API key provided",
    "code": "invalid_api_key"
  }
}
```

Main Error Types:

-   `invalid_request_error`: Invalid request parameters
-   `authentication_error`: Authentication related error
-   `rate_limit_error`: Rate limit exceeded
-   `server_error`: Internal server error